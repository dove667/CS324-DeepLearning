{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "What is PyTorch?\n",
    "================\n",
    "https://pytorch.org/docs/stable/index.html\n",
    "\n",
    "It’s a Python-based scientific computing package targeted at two sets of\n",
    "audiences:\n",
    "\n",
    "-  A replacement for NumPy to use the power of GPUs\n",
    "-  a deep learning research platform that provides maximum flexibility\n",
    "   and speed\n",
    "\n",
    "\n",
    "NumPy Bridge\n",
    "------------\n",
    "1. Tensors are similar to NumPy’s arrays, with the addition being that\n",
    "Tensors can also be used on a GPU to accelerate computing.  \n",
    "\n",
    "2. All the Tensors on the CPU except a CharTensor support converting to\n",
    "NumPy and back. Converting a Torch Tensor to a NumPy array and vice versa is a breeze.  \n",
    "\n",
    "3. The Torch Tensor and NumPy array will share their underlying memory\n",
    "locations (if the Torch Tensor is on CPU), and changing one will change\n",
    "the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPU available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine your GPUs are available for pytorch (False for CPU version of pytorch)\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### array <-> tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "[[1 2]\n",
      " [3 4]]\n",
      "\n",
      "[[1 2]\n",
      " [3 4]]\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "data = [[1, 2],[3, 4]]\n",
    "# tensor to array\n",
    "x_tensor = torch.tensor(data); print(x_tensor)\n",
    "x_tensor2array = x_tensor.numpy(); print(x_tensor2array); print()\n",
    "# array to tensor\n",
    "x_array = np.array(data); print(x_array)\n",
    "x_array2tenor = torch.from_numpy(x_array); print(x_array2tenor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "data = [[1, 2],[3, 4]]\n",
    "x = torch.tensor(data); print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[0.0996, 0.3534, 0.1315],\n",
      "        [0.3842, 0.2708, 0.7285]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[0.6364, 0.5760, 0.6136],\n",
      "        [0.7853, 0.9234, 0.9571]])\n"
     ]
    }
   ],
   "source": [
    "# empty/rand/ones/zeros/eye(), xxx_like()\n",
    "# the difference is you can fill dimensions without brackets at the beginning for these functions\n",
    "x = torch.empty(2, 3); print(x)\n",
    "x = torch.rand(2, 3); print(x) # initialization from the Gaussian distribution of N(0,1)\n",
    "# cuda() means translating your tensors into GPUs\n",
    "x = torch.zeros(2, 3, dtype=torch.float)#.cuda(); \n",
    "print(x) # if your device is CPU, please delete the cuda()\n",
    "y = torch.rand_like(x) # _like means the same shape, data type and device(GPU or CPU)\n",
    "print(y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# get shape\n",
    "print(x.shape)\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have a one element tensor, use ``.item()`` to get the value as a Python number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0293])\n",
      "0.029287267476320267\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A bunch of operations in numpy have corresponding functions in torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(10)\n",
    "# torch.stack()\n",
    "# torch.concatenate()\n",
    "# torch.squeeze()/unsqueeze()\n",
    "# torch.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2, 3])\n",
      "torch.Size([3, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "# permute -> transpose in numpy, to switch the order of dimensions\n",
    "x = torch.arange(24).reshape(2,3,4)\n",
    "y = x.permute([2,0,1]); print(y.shape)\n",
    "y = x.transpose(0,1); print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computation of Tensors\n",
    "Note: The default calculation is element-wise calculation (+ - * /)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "tensor([[0.8653, 1.3147, 2.9124],\n",
      "        [3.4924, 4.5531, 5.5009]])\n",
      "tensor([[0.0000, 0.3147, 1.8249],\n",
      "        [1.4772, 2.2126, 2.5043]])\n",
      "tensor([[0.0000, 3.1774, 2.1919],\n",
      "        [6.0927, 7.2315, 9.9830]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(6).reshape(2,3); print(x)\n",
    "y = torch.rand(2, 3)\n",
    "print(x + y)\n",
    "print(x*y)\n",
    "print(x/y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4252, 0.0802, 0.3347],\n",
      "        [0.3010, 0.6351, 0.8638]])\n",
      "tensor([[0.9065, 0.3697, 0.9805],\n",
      "        [0.4535, 0.2678, 0.6335]])\n",
      "tensor([[0.3854, 0.0296, 0.3282],\n",
      "        [0.1365, 0.1701, 0.5472]])\n",
      "torch.Size([2, 3])\n",
      "tensor([[0.3854, 0.0296, 0.3282],\n",
      "        [0.1365, 0.1701, 0.5472]])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# torch.mul() equals \"*\": Element-wise multiplication\n",
    "a = torch.rand(2, 3);print(a)\n",
    "b = torch.rand(2, 3);print(b)\n",
    "print(torch.mul(a, b))\n",
    "print(torch.mul(a, b).size())\n",
    "print((a*b))\n",
    "print((a*b).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# torch.mm(): the common mathematical matrix multiplication\n",
    "mat1 = torch.randn(2, 3)\n",
    "mat2 = torch.randn(3, 3)\n",
    "print(torch.mm(mat1, mat2).size())\n",
    "print((mat1 @ mat2).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 5])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.matmul() equals \"@\": Matrix product of two tensors, it includes matrix multiplication methods of different dimensions\n",
    "tensor1 = torch.randn(10, 3, 4)\n",
    "tensor2 = torch.randn(10, 4, 5)\n",
    "torch.matmul(tensor1, tensor2).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read later:**\n",
    "\n",
    "\n",
    "  100+ Tensor operations, including transposing, indexing, slicing,\n",
    "  mathematical operations, linear algebra, random numbers, etc.,\n",
    "  are described [here](https://pytorch.org/docs/torch)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CUDA Tensors\n",
    "------------\n",
    "\n",
    "Tensors can be moved onto any device using the ``.to`` method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]], device='cuda:0')\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# let us run this cell only if CUDA is available\n",
    "# We will use ``torch.device`` objects to move tensors in and out of GPU\n",
    "x = torch.arange(6).reshape(2,3) # x created in CPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
    "    # y.cuda() is also an easy method to move onto the default GPU\n",
    "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise1\n",
    "Broadcasting is an underlying rules for dealing with unpaired tensors.  \n",
    "[Broadcasting tutorial](https://deeplearninguniversity.com/pytorch/pytorch-broadcasting/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise2\n",
    "[Pytorch official website](https://pytorch.org/tutorials/) has provided sufficient tutorials for beginners.\n",
    "Familiarize yourself with PyTorch concepts and modules. Learn how to load data, build deep neural networks, train and save your models in [quickstart guide](https://pytorch.org/tutorials/beginner/basics/intro.html).\n",
    "\n",
    "We also provide old version of the pytorch tutorials in file folder \"old_pytorch_tutorials\". The tutorials in [Pytorch official website](https://pytorch.org/tutorials/) is more recommended.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
